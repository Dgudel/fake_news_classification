{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8cf56d-d05f-4cba-a976-c8f98aa4d985",
   "metadata": {},
   "source": [
    "# A deep learning model for fake news classification based on the pre-trained transformer model Distilbert (model No.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3c8bc-756c-49d4-9931-32df75f298b3",
   "metadata": {},
   "source": [
    "In this file the creating and assessing a deep learning model based on the pre-trained transformer model Distilbert is presented. These parameters were used for this model:\n",
    "- learning rate 0.001 (training) 0.0001 (fine-tuning);\n",
    "- maximum sequence length was set to 300;\n",
    "- training-validation-test split 0.4x0.4x0.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea7c26",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf93a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"import os\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport time\\n\\nimport seaborn as sns\\n\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\\nfrom torch import optim\\nfrom torchsummary import summary\\nfrom torchmetrics.classification import Accuracy\\nfrom torchvision.transforms import ToTensor, Lambda\\nimport pytorch_lightning as pl\\nfrom pytorch_lightning.callbacks import ModelCheckpoint\\n\\nimport transformers\\nfrom transformers import (\\n    AutoTokenizer,\\n    AutoModelForSequenceClassification,\\n    RobertaConfig, \\n    RobertaForSequenceClassification,\\n    DistilBertTokenizer,\\n    DistilBertForMaskedLM,\\n    DistilBertModel,\\n    DistilBertForSequenceClassification,\\n    DistilBertConfig,\\n    pipeline\\n)\\n\\nimport pickle\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom tokenizers import trainers, models, Tokenizer, pre_tokenizers\\n\\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_validate\\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, \\\\\\nrecall_score, confusion_matrix, make_scorer, classification_report,\\\\\\n roc_auc_score, average_precision_score, log_loss\\n\\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\\nfrom sklearn.utils.class_weight import compute_sample_weight, compute_class_weight\\n\\n\\nimport joblib\\n\\nimport gensim\\nfrom nltk.stem import WordNetLemmatizer, PorterStemmer\\nfrom nltk.tokenize import word_tokenize\\nfrom textblob import TextBlob\\nfrom wordcloud import WordCloud, STOPWORDS\\n\\nfrom collections import defaultdict\\nfrom collections import Counter\\nfrom typing import Any, List, Tuple, Union, Dict\\n\\nfrom fake_news_dataset_distilbert import FakeNewsDatasetDistilbert1\\nimport warnings\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"import os\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport time\\n\\nimport seaborn as sns\\n\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\\nfrom torch import optim\\nfrom torchsummary import summary\\nfrom torchmetrics.classification import Accuracy\\nfrom torchvision.transforms import ToTensor, Lambda\\nimport pytorch_lightning as pl\\nfrom pytorch_lightning.callbacks import ModelCheckpoint\\n\\nimport transformers\\nfrom transformers import (\\n    AutoTokenizer,\\n    AutoModelForSequenceClassification,\\n    RobertaConfig,\\n    RobertaForSequenceClassification,\\n    DistilBertTokenizer,\\n    DistilBertForMaskedLM,\\n    DistilBertModel,\\n    DistilBertForSequenceClassification,\\n    DistilBertConfig,\\n    pipeline,\\n)\\n\\nimport pickle\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom tokenizers import trainers, models, Tokenizer, pre_tokenizers\\n\\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_validate\\nfrom sklearn.metrics import (\\n    accuracy_score,\\n    f1_score,\\n    precision_score,\\n    recall_score,\\n    confusion_matrix,\\n    make_scorer,\\n    classification_report,\\n    roc_auc_score,\\n    average_precision_score,\\n    log_loss,\\n)\\n\\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\\nfrom sklearn.utils.class_weight import compute_sample_weight, compute_class_weight\\n\\n\\nimport joblib\\n\\nimport gensim\\nfrom nltk.stem import WordNetLemmatizer, PorterStemmer\\nfrom nltk.tokenize import word_tokenize\\nfrom textblob import TextBlob\\nfrom wordcloud import WordCloud, STOPWORDS\\n\\nfrom collections import defaultdict\\nfrom collections import Counter\\nfrom typing import Any, List, Tuple, Union, Dict\\n\\nfrom fake_news_dataset_distilbert import FakeNewsDatasetDistilbert1\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    RobertaConfig, \n",
    "    RobertaForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertForMaskedLM,\n",
    "    DistilBertModel,\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertConfig,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tokenizers import trainers, models, Tokenizer, pre_tokenizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, \\\n",
    "recall_score, confusion_matrix, make_scorer, classification_report,\\\n",
    " roc_auc_score, average_precision_score, log_loss\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.utils.class_weight import compute_sample_weight, compute_class_weight\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "import gensim\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from typing import Any, List, Tuple, Union, Dict\n",
    "\n",
    "from fake_news_dataset_distilbert import FakeNewsDatasetDistilbert1\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd4a099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d5ef4",
   "metadata": {},
   "source": [
    "### Importing, tokenizing and splitting the datasetÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e758bf-21d0-4a72-a7fe-8c6e81fdf864",
   "metadata": {},
   "source": [
    "the concatenated dataset with columns for fake and true news articles' text and titles was uploaded as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c12d059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"news = pd.read_csv(\\\"news.csv\\\")\";\n",
       "                var nbb_formatted_code = \"news = pd.read_csv(\\\"news.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news = pd.read_csv(\"news.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafccd19-5ac2-440e-aa36-cfe08b9cd000",
   "metadata": {},
   "source": [
    "Text and titles were combined into a single text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c2e0a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"news[\\\"title_text\\\"] = news[\\\"title\\\"] + \\\" \\\" + news[\\\"text\\\"]\";\n",
       "                var nbb_formatted_code = \"news[\\\"title_text\\\"] = news[\\\"title\\\"] + \\\" \\\" + news[\\\"text\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news[\"title_text\"] = news[\"title\"] + \" \" + news[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6cab1-c3bb-472d-abf3-7763b120095e",
   "metadata": {},
   "source": [
    "Other columns were droped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36ae2bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"X = news.drop(\\n    [\\\"title\\\", \\\"text\\\", \\\"subject\\\", \\\"date\\\", \\\"Unnamed: 0\\\"],\\n    axis=1,\\n)\\n\\nX_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\\nX_train, X_val = train_test_split(X_train, test_size=0.5, random_state=42)\";\n",
       "                var nbb_formatted_code = \"X = news.drop(\\n    [\\\"title\\\", \\\"text\\\", \\\"subject\\\", \\\"date\\\", \\\"Unnamed: 0\\\"],\\n    axis=1,\\n)\\n\\nX_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\\nX_train, X_val = train_test_split(X_train, test_size=0.5, random_state=42)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = news.drop(\n",
    "    [\"title\", \"text\", \"subject\", \"date\", \"Unnamed: 0\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1c86e8-31db-49e0-b61c-c41e2b9de09d",
   "metadata": {},
   "source": [
    "Train, validation and test datasets were created with the Pytorch Lightning class. The class encoded the data into tensors with the Roberta tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d961efb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"train_dataset = FakeNewsDatasetDistilbert1(X_train, labels_available=True)\\nval_dataset = FakeNewsDatasetDistilbert1(X_val, labels_available=True)\\ntest_dataset = FakeNewsDatasetDistilbert1(X_test, labels_available=True)\";\n",
       "                var nbb_formatted_code = \"train_dataset = FakeNewsDatasetDistilbert1(X_train, labels_available=True)\\nval_dataset = FakeNewsDatasetDistilbert1(X_val, labels_available=True)\\ntest_dataset = FakeNewsDatasetDistilbert1(X_test, labels_available=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = FakeNewsDatasetDistilbert1(X_train, labels_available=True)\n",
    "val_dataset = FakeNewsDatasetDistilbert1(X_val, labels_available=True)\n",
    "test_dataset = FakeNewsDatasetDistilbert1(X_test, labels_available=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7611a4-9978-4c61-883a-d8191fe8d3fa",
   "metadata": {},
   "source": [
    "The data was encoded correctly (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2b38f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17959"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"len(\\n    train_dataset,\\n)\";\n",
       "                var nbb_formatted_code = \"len(\\n    train_dataset,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(\n",
    "    train_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ddc5251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1456,  3577,  2196,  1185,  2951,  1122,  1110,  3021,  1164,\n",
       "          2520,   131,   158,   119,   156,   119,  2078, 22751,  1708,  3048,\n",
       "         15740, 18082,  2249,   113, 11336, 27603,   114,   118,  1109,  1426,\n",
       "          1951,  1163,  9031,  1115,  1103,  1244,  1311,  1156,  1129,  1501,\n",
       "          1106,  2520,  1106,  1456,  3577,  1165,  1103,  1159,  1110,  1268,\n",
       "          1133,  1115,  1122,  1180,  1136,  3333,  1208,  1272,   153, 15136,\n",
       "          4873,  4993,  1144,  2602,  1185,  2951,  1104,   170, 21623,  1106,\n",
       "          9700,  1157,  8233,  1105,  4272,  5193,   119,  2711,   158,   119,\n",
       "           156,   119,  2909,  1104,  1426, 10896, 22430, 18608,   188,  2906,\n",
       "          1113,  9667,  1106,  1838,  7430,  1114,  1456,  3577,  1443,  3073,\n",
       "           118,  2975,   117,  1426,  1951,  2910,  1116,  9462,  9644, 11896,\n",
       "         10232,  1204,  1163,  1175,  1156,  1148,  1138,  1106,  1129,   170,\n",
       "          1669,  1104,  5017,  1107,  1134,   153, 15136,  4873,  4993, 28117,\n",
       "         20080, 22367,  5193,  1196,  1251,  7624,  1180,  3295,   119, 22430,\n",
       "         18608,   117,  1107,   170,  4055,  1106,   170,  1994,  1341,  4890,\n",
       "          1113,  9667,   117,  1225,  1136, 12252,  4586,  1216,   170, 16020,\n",
       "          1112,   170,  8875,  1115,  1456,  3577,  1538,  2283,  3075,  1104,\n",
       "          7430,   119, 11896, 10232,  1204,   117,  3522,  1120,  1103,  1426,\n",
       "          1951,   188,  3828,  4094,  1158,   117,  6744,  1115, 22430, 18608,\n",
       "          1108,  1136,  7046,  1207,  2818,  1107,  1117,  4055,   117,  1256,\n",
       "          1463,  1119,  1691,  1106,  1171,  1283,  1121,   170,  2501,   158,\n",
       "           119,   156,   119,  4555,  1115,   153, 15136,  4873,  4993,  1538,\n",
       "          1148,  4392,  1115,  1251,  7624,  1156,  1138,  1106,  1129,  1164,\n",
       "          2368,  1146,  1157,  4272,   170, 22972,  1348,   119,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"test_dataset[8]\";\n",
       "                var nbb_formatted_code = \"test_dataset[8]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6282fddc-dd9c-4da8-b8ce-96deb271a78c",
   "metadata": {},
   "source": [
    "The class as a Pytortch Lightning model was created which uses the pretrained Ditilbert model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f326e01-7475-4c08-aa2c-674caff1c9d3",
   "metadata": {},
   "source": [
    "### Creating the model class and instantiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "810c3972-f9f7-4331-82c1-944f8a12d06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"lr = 0.001\";\n",
       "                var nbb_formatted_code = \"lr = 0.001\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e742a62-a800-4248-98ad-c4cc67950914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class FakeNewsModelDistilbert(pl.LightningModule):\\n    def __init__(self, num_classes: int = 2, lr: float = lr):\\n        super().__init__()\\n        config = DistilBertConfig(\\n            num_labels=num_classes,\\n            lr = lr\\n        )\\n        self.distilbert = DistilBertForSequenceClassification.from_pretrained(\\n            \\\"distilbert-base-cased\\\", config=config, ignore_mismatched_sizes=True\\n        )\\n        self.distilbert_grad(False)\\n        self.lr = lr\\n        self.train_losses = []\\n        self.val_losses = []\\n    \\n    def distilbert_grad(self, requires_grad: bool):\\n        \\\"\\\"\\\"\\n        Freezes or unfreezes the parameters of the base DistilBERT model for fine-tuning.\\n        \\\"\\\"\\\"\\n        for param in self.distilbert.base_model.parameters():\\n            param.requires_grad = requires_grad\\n    \\n    def forward(self, input_ids, attention_mask, labels=None):\\n        if labels is not None:\\n            outputs = self.distilbert(\\n                input_ids=input_ids, attention_mask=attention_mask, labels=labels\\n            )\\n            loss, logits = outputs.loss, outputs.logits\\n            return loss, logits\\n        else:\\n            logits = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)[0]\\n            return logits\\n    \\n\\n    def configure_optimizers(self):\\n        \\\"\\\"\\\"\\n        Configures the optimizer for training the model.\\n\\n        Returns:\\n            optimizer (optim.AdamW): AdamW optimizer with specified learning rate and epsilon.\\n        \\\"\\\"\\\"\\n        return optim.AdamW(\\n            [p for p in self.parameters() if p.requires_grad], lr=self.lr, eps=1e-08\\n        )\\n\\n    def train_dataloader(self):\\n        \\\"\\\"\\\"\\n        Returns a DataLoader for the training dataset.\\n\\n        Returns:\\n            loader (DataLoader): DataLoader for the training dataset.\\n        \\\"\\\"\\\"\\n        dataset = FakeNewsDatasetDistilbert(X_train)\\n        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=3)\\n        return loader\\n\\n    def val_dataloader(self):\\n        \\\"\\\"\\\"\\n        Returns a DataLoader for the validation dataset.\\n\\n        Returns:\\n            loader (DataLoader): DataLoader for the validation dataset.\\n        \\\"\\\"\\\"\\n        dataset = FakeNewsDatasetDistilbert(X_val)\\n        loader = DataLoader(\\n            dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n        )\\n        return loader\\n\\n    def test_dataloader(self):\\n        \\\"\\\"\\\"\\n        Returns a DataLoader for the test dataset.\\n\\n        Returns:\\n            loader (DataLoader): DataLoader for the test dataset.\\n        \\\"\\\"\\\"\\n        dataset = FakeNewsDatasetDistilbert(X_test)\\n        loader = DataLoader(\\n            dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n        )\\n        return loader\\n\\n    def training_step(self, batch, batch_idx):\\n        \\\"\\\"\\\"\\n        Performs a single training step.\\n\\n        Args:\\n            batch (torch.Tensor): Batch of data.\\n            batch_idx (int): Index of the batch.\\n\\n        Returns:\\n            Loss (torch.Tensor): Loss value.\\n        \\\"\\\"\\\"\\n        bert_input = batch\\n        loss, logits = self(**bert_input)\\n        loss = loss.mean()\\n        self.log(\\\"train_loss\\\", loss)\\n        self.train_losses.append(loss)\\n        return loss\\n\\n    def validation_step(self, val_batch, batch_idx):\\n        \\\"\\\"\\\"\\n        Performs a single validation step.\\n\\n        Args:\\n            val_batch (torch.Tensor): Batch of data.\\n            batch_idx (int): Index of the batch.\\n\\n        Returns:\\n            loss (torch.Tensor): Loss value.\\n        \\\"\\\"\\\"\\n        bert_input = val_batch\\n        loss, logits = self(**bert_input)\\n        loss = loss.mean()\\n        self.log(\\\"val_loss\\\", loss)\\n        self.val_losses.append(loss)\\n        return loss\\n\\n    def test_step(self, test_batch, batch_idx):\\n        \\\"\\\"\\\"\\n        Performs a single testing step.\\n\\n        Args:\\n            test_batch (torch.Tensor): Batch of data.\\n            batch_idx (int): Index of the batch.\\n\\n        Returns:\\n            logits (torch.Tensor): Logits output from the model.\\n        \\\"\\\"\\\"\\n        bert_input = test_batch\\n        logits = self(**bert_input)\\n        return logits\\n\\n    def test_epoch_end(self, outputs):\\n        \\\"\\\"\\\"\\n        Performs operations on the outputs of the test data.\\n\\n        Args:\\n            outputs (list): List of outputs from the test data.\\n\\n        Returns:\\n            all_logits (torch.Tensor): Concatenated logits from all batches.\\n        \\\"\\\"\\\"\\n        all_logits = torch.cat(outputs, dim=0)\\n        return all_logits\\n\\n    def on_train_epoch_end(self):\\n        \\\"\\\"\\\"\\n        Performs operations at the end of each training epoch.\\n        \\\"\\\"\\\"\\n        train_loss = torch.stack(self.train_losses).mean()\\n        self.log(\\\"avg_train_loss\\\", train_loss)\\n\\n    def on_validation_epoch_end(self):\\n        \\\"\\\"\\\"\\n        Performs operations at the end of each validation epoch.\\n        \\\"\\\"\\\"\\n        val_loss = torch.stack(self.val_losses).mean()\\n        self.log(\\\"ag_val_loss\\\", val_loss)\";\n",
       "                var nbb_formatted_code = \"class FakeNewsModelDistilbert(pl.LightningModule):\\n    def __init__(self, num_classes: int = 2, lr: float = lr):\\n        super().__init__()\\n        config = DistilBertConfig(num_labels=num_classes, lr=lr)\\n        self.distilbert = DistilBertForSequenceClassification.from_pretrained(\\n            \\\"distilbert-base-cased\\\", config=config, ignore_mismatched_sizes=True\\n        )\\n        self.distilbert_grad(False)\\n        self.lr = lr\\n        self.train_losses = []\\n        self.val_losses = []\\n\\n    def distilbert_grad(self, requires_grad: bool):\\n        \\\"\\\"\\\"\\n        Freezes or unfreezes the parameters of the base DistilBERT model for fine-tuning.\\n        \\\"\\\"\\\"\\n        for param in self.distilbert.base_model.parameters():\\n            param.requires_grad = requires_grad\\n\\n    def forward(self, input_ids, attention_mask, labels=None):\\n        if labels is not None:\\n            outputs = self.distilbert(\\n                input_ids=input_ids, attention_mask=attention_mask, labels=labels\\n            )\\n            loss, logits = outputs.loss, outputs.logits\\n            return loss, logits\\n        else:\\n            logits = self.distilbert(\\n                input_ids=input_ids, attention_mask=attention_mask\\n            )[0]\\n            return logits\\n\\n    def configure_optimizers(self):\\n        \\\"\\\"\\\"\\n        Configures the optimizer for training the model.\\n\\n        Returns:\\n            optimizer (optim.AdamW): AdamW optimizer with specified learning rate and epsilon.\\n        \\\"\\\"\\\"\\n        return optim.AdamW(\\n            [p for p in self.parameters() if p.requires_grad], lr=self.lr, eps=1e-08\\n        )\\n\\n    def train_dataloader(self):\\n        \\\"\\\"\\\"\\n        Returns a DataLoader for the training dataset.\\n\\n        Returns:\\n            loader (DataLoader): DataLoader for the training dataset.\\n        \\\"\\\"\\\"\\n        dataset = FakeNewsDatasetDistilbert(X_train)\\n        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=3)\\n        return loader\\n\\n    def val_dataloader(self):\\n        \\\"\\\"\\\"\\n        Returns a DataLoader for the validation dataset.\\n\\n        Returns:\\n            loader (DataLoader): DataLoader for the validation dataset.\\n        \\\"\\\"\\\"\\n        dataset = FakeNewsDatasetDistilbert(X_val)\\n        loader = DataLoader(\\n            dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n        )\\n        return loader\\n\\n    def test_dataloader(self):\\n        \\\"\\\"\\\"\\n        Returns a DataLoader for the test dataset.\\n\\n        Returns:\\n            loader (DataLoader): DataLoader for the test dataset.\\n        \\\"\\\"\\\"\\n        dataset = FakeNewsDatasetDistilbert(X_test)\\n        loader = DataLoader(\\n            dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n        )\\n        return loader\\n\\n    def training_step(self, batch, batch_idx):\\n        \\\"\\\"\\\"\\n        Performs a single training step.\\n\\n        Args:\\n            batch (torch.Tensor): Batch of data.\\n            batch_idx (int): Index of the batch.\\n\\n        Returns:\\n            Loss (torch.Tensor): Loss value.\\n        \\\"\\\"\\\"\\n        bert_input = batch\\n        loss, logits = self(**bert_input)\\n        loss = loss.mean()\\n        self.log(\\\"train_loss\\\", loss)\\n        self.train_losses.append(loss)\\n        return loss\\n\\n    def validation_step(self, val_batch, batch_idx):\\n        \\\"\\\"\\\"\\n        Performs a single validation step.\\n\\n        Args:\\n            val_batch (torch.Tensor): Batch of data.\\n            batch_idx (int): Index of the batch.\\n\\n        Returns:\\n            loss (torch.Tensor): Loss value.\\n        \\\"\\\"\\\"\\n        bert_input = val_batch\\n        loss, logits = self(**bert_input)\\n        loss = loss.mean()\\n        self.log(\\\"val_loss\\\", loss)\\n        self.val_losses.append(loss)\\n        return loss\\n\\n    def test_step(self, test_batch, batch_idx):\\n        \\\"\\\"\\\"\\n        Performs a single testing step.\\n\\n        Args:\\n            test_batch (torch.Tensor): Batch of data.\\n            batch_idx (int): Index of the batch.\\n\\n        Returns:\\n            logits (torch.Tensor): Logits output from the model.\\n        \\\"\\\"\\\"\\n        bert_input = test_batch\\n        logits = self(**bert_input)\\n        return logits\\n\\n    def test_epoch_end(self, outputs):\\n        \\\"\\\"\\\"\\n        Performs operations on the outputs of the test data.\\n\\n        Args:\\n            outputs (list): List of outputs from the test data.\\n\\n        Returns:\\n            all_logits (torch.Tensor): Concatenated logits from all batches.\\n        \\\"\\\"\\\"\\n        all_logits = torch.cat(outputs, dim=0)\\n        return all_logits\\n\\n    def on_train_epoch_end(self):\\n        \\\"\\\"\\\"\\n        Performs operations at the end of each training epoch.\\n        \\\"\\\"\\\"\\n        train_loss = torch.stack(self.train_losses).mean()\\n        self.log(\\\"avg_train_loss\\\", train_loss)\\n\\n    def on_validation_epoch_end(self):\\n        \\\"\\\"\\\"\\n        Performs operations at the end of each validation epoch.\\n        \\\"\\\"\\\"\\n        val_loss = torch.stack(self.val_losses).mean()\\n        self.log(\\\"ag_val_loss\\\", val_loss)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FakeNewsModelDistilbert(pl.LightningModule):\n",
    "    def __init__(self, num_classes: int = 2, lr: float = lr):\n",
    "        super().__init__()\n",
    "        config = DistilBertConfig(\n",
    "            num_labels=num_classes,\n",
    "            lr = lr\n",
    "        )\n",
    "        self.distilbert = DistilBertForSequenceClassification.from_pretrained(\n",
    "            \"distilbert-base-cased\", config=config, ignore_mismatched_sizes=True\n",
    "        )\n",
    "        self.distilbert_grad(False)\n",
    "        self.lr = lr\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "    \n",
    "    def distilbert_grad(self, requires_grad: bool):\n",
    "        \"\"\"\n",
    "        Freezes or unfreezes the parameters of the base DistilBERT model for fine-tuning.\n",
    "        \"\"\"\n",
    "        for param in self.distilbert.base_model.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        if labels is not None:\n",
    "            outputs = self.distilbert(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "            )\n",
    "            loss, logits = outputs.loss, outputs.logits\n",
    "            return loss, logits\n",
    "        else:\n",
    "            logits = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "            return logits\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configures the optimizer for training the model.\n",
    "\n",
    "        Returns:\n",
    "            optimizer (optim.AdamW): AdamW optimizer with specified learning rate and epsilon.\n",
    "        \"\"\"\n",
    "        return optim.AdamW(\n",
    "            [p for p in self.parameters() if p.requires_grad], lr=self.lr, eps=1e-08\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Returns a DataLoader for the training dataset.\n",
    "\n",
    "        Returns:\n",
    "            loader (DataLoader): DataLoader for the training dataset.\n",
    "        \"\"\"\n",
    "        dataset = FakeNewsDatasetDistilbert(X_train)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "        return loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"\n",
    "        Returns a DataLoader for the validation dataset.\n",
    "\n",
    "        Returns:\n",
    "            loader (DataLoader): DataLoader for the validation dataset.\n",
    "        \"\"\"\n",
    "        dataset = FakeNewsDatasetDistilbert(X_val)\n",
    "        loader = DataLoader(\n",
    "            dataset, batch_size=batch_size, shuffle=False, num_workers=3\n",
    "        )\n",
    "        return loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        \"\"\"\n",
    "        Returns a DataLoader for the test dataset.\n",
    "\n",
    "        Returns:\n",
    "            loader (DataLoader): DataLoader for the test dataset.\n",
    "        \"\"\"\n",
    "        dataset = FakeNewsDatasetDistilbert(X_test)\n",
    "        loader = DataLoader(\n",
    "            dataset, batch_size=batch_size, shuffle=False, num_workers=3\n",
    "        )\n",
    "        return loader\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs a single training step.\n",
    "\n",
    "        Args:\n",
    "            batch (torch.Tensor): Batch of data.\n",
    "            batch_idx (int): Index of the batch.\n",
    "\n",
    "        Returns:\n",
    "            Loss (torch.Tensor): Loss value.\n",
    "        \"\"\"\n",
    "        bert_input = batch\n",
    "        loss, logits = self(**bert_input)\n",
    "        loss = loss.mean()\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.train_losses.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs a single validation step.\n",
    "\n",
    "        Args:\n",
    "            val_batch (torch.Tensor): Batch of data.\n",
    "            batch_idx (int): Index of the batch.\n",
    "\n",
    "        Returns:\n",
    "            loss (torch.Tensor): Loss value.\n",
    "        \"\"\"\n",
    "        bert_input = val_batch\n",
    "        loss, logits = self(**bert_input)\n",
    "        loss = loss.mean()\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.val_losses.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs a single testing step.\n",
    "\n",
    "        Args:\n",
    "            test_batch (torch.Tensor): Batch of data.\n",
    "            batch_idx (int): Index of the batch.\n",
    "\n",
    "        Returns:\n",
    "            logits (torch.Tensor): Logits output from the model.\n",
    "        \"\"\"\n",
    "        bert_input = test_batch\n",
    "        logits = self(**bert_input)\n",
    "        return logits\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        \"\"\"\n",
    "        Performs operations on the outputs of the test data.\n",
    "\n",
    "        Args:\n",
    "            outputs (list): List of outputs from the test data.\n",
    "\n",
    "        Returns:\n",
    "            all_logits (torch.Tensor): Concatenated logits from all batches.\n",
    "        \"\"\"\n",
    "        all_logits = torch.cat(outputs, dim=0)\n",
    "        return all_logits\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Performs operations at the end of each training epoch.\n",
    "        \"\"\"\n",
    "        train_loss = torch.stack(self.train_losses).mean()\n",
    "        self.log(\"avg_train_loss\", train_loss)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Performs operations at the end of each validation epoch.\n",
    "        \"\"\"\n",
    "        val_loss = torch.stack(self.val_losses).mean()\n",
    "        self.log(\"ag_val_loss\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6efa3d-ab26-4e69-bd84-4bc5b9d28010",
   "metadata": {},
   "source": [
    "Batch size 5 was used for loading the data. Model was initalized, GPU processor was attached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "880d9481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"batch_size = 5\";\n",
       "                var nbb_formatted_code = \"batch_size = 5\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "866bccac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized because the shapes did not match:\n",
      "- distilbert.embeddings.word_embeddings.weight: found shape torch.Size([28996, 768]) in the checkpoint and torch.Size([30522, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"model = FakeNewsModelDistilbert()\";\n",
       "                var nbb_formatted_code = \"model = FakeNewsModelDistilbert()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = FakeNewsModelDistilbert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9637c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"device = torch.device(\\\"mps\\\")\";\n",
       "                var nbb_formatted_code = \"device = torch.device(\\\"mps\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32d79357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FakeNewsModelDistilbert(\n",
       "  (distilbert): DistilBertForSequenceClassification(\n",
       "    (distilbert): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0-5): 6 x TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"model.to(device)\";\n",
       "                var nbb_formatted_code = \"model.to(device)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31485f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"tensorboard_logger = pl.loggers.TensorBoardLogger(\\n    save_dir=\\\"./logs\\\", name=\\\"single_label_classification\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"tensorboard_logger = pl.loggers.TensorBoardLogger(\\n    save_dir=\\\"./logs\\\", name=\\\"single_label_classification\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard_logger = pl.loggers.TensorBoardLogger(\n",
    "    save_dir=\"./logs\", name=\"single_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14380fd8",
   "metadata": {},
   "source": [
    "### Specifying callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b590e7b",
   "metadata": {},
   "source": [
    "The callback classes were created and callbacks initialized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5b0c115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"early_stopping_callback = pl.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min')\";\n",
       "                var nbb_formatted_code = \"early_stopping_callback = pl.callbacks.EarlyStopping(\\n    monitor=\\\"val_loss\\\", patience=3, mode=\\\"min\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stopping_callback = pl.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e4b8ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"\\ncheckpoint_callback = ModelCheckpoint(\\n        dirpath=\\\"models/\\\",\\n        filename=f'{{epoch}}-{{val_loss:.2f}}',\\n        monitor=\\\"val_loss\\\",\\n        save_top_k=3,\\n        mode=\\\"min\\\",\\n        every_n_epochs=1,\\n    )\";\n",
       "                var nbb_formatted_code = \"checkpoint_callback = ModelCheckpoint(\\n    dirpath=\\\"models/\\\",\\n    filename=f\\\"{{epoch}}-{{val_loss:.2f}}\\\",\\n    monitor=\\\"val_loss\\\",\\n    save_top_k=3,\\n    mode=\\\"min\\\",\\n    every_n_epochs=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"models/\",\n",
    "        filename=f'{{epoch}}-{{val_loss:.2f}}',\n",
    "        monitor=\"val_loss\",\n",
    "        save_top_k=3,\n",
    "        mode=\"min\",\n",
    "        every_n_epochs=1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fe280b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"class ValidationLogCollectorCallback(pl.Callback):\\n    \\\"\\\"\\\"\\n    A PyTorch Lightning callback that collects validation metrics at the end of each validation epoch.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self):\\n        \\\"\\\"\\\"\\n        Initializes the ValidationLogCollectorCallback.\\n        \\\"\\\"\\\"\\n        super().__init__()\\n        self.validation_metrics = []\\n\\n    def on_validation_epoch_end(\\n        self, trainer: pl.Trainer, pl_module: pl.LightningModule\\n    ):\\n        \\\"\\\"\\\"\\n        Collects the validation metrics at the end of each validation epoch.\\n\\n        Args:\\n            trainer (pl.Trainer): The PyTorch Lightning trainer object.\\n            pl_module (pl.LightningModule): The PyTorch Lightning module being trained.\\n        \\\"\\\"\\\"\\n        metrics = trainer.callback_metrics\\n        self.validation_metrics.append(metrics)\\n\\n    def get_metrics_dataframe(self) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Returns a Pandas DataFrame containing the collected validation metrics.\\n\\n        Returns:\\n            pd.DataFrame: A Pandas DataFrame containing the collected validation metrics.\\n        \\\"\\\"\\\"\\n        return pd.DataFrame(self.validation_metrics)\";\n",
       "                var nbb_formatted_code = \"class ValidationLogCollectorCallback(pl.Callback):\\n    \\\"\\\"\\\"\\n    A PyTorch Lightning callback that collects validation metrics at the end of each validation epoch.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self):\\n        \\\"\\\"\\\"\\n        Initializes the ValidationLogCollectorCallback.\\n        \\\"\\\"\\\"\\n        super().__init__()\\n        self.validation_metrics = []\\n\\n    def on_validation_epoch_end(\\n        self, trainer: pl.Trainer, pl_module: pl.LightningModule\\n    ):\\n        \\\"\\\"\\\"\\n        Collects the validation metrics at the end of each validation epoch.\\n\\n        Args:\\n            trainer (pl.Trainer): The PyTorch Lightning trainer object.\\n            pl_module (pl.LightningModule): The PyTorch Lightning module being trained.\\n        \\\"\\\"\\\"\\n        metrics = trainer.callback_metrics\\n        self.validation_metrics.append(metrics)\\n\\n    def get_metrics_dataframe(self) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Returns a Pandas DataFrame containing the collected validation metrics.\\n\\n        Returns:\\n            pd.DataFrame: A Pandas DataFrame containing the collected validation metrics.\\n        \\\"\\\"\\\"\\n        return pd.DataFrame(self.validation_metrics)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ValidationLogCollectorCallback(pl.Callback):\n",
    "    \"\"\"\n",
    "    A PyTorch Lightning callback that collects validation metrics at the end of each validation epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the ValidationLogCollectorCallback.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.validation_metrics = []\n",
    "\n",
    "    def on_validation_epoch_end(\n",
    "        self, trainer: pl.Trainer, pl_module: pl.LightningModule\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Collects the validation metrics at the end of each validation epoch.\n",
    "\n",
    "        Args:\n",
    "            trainer (pl.Trainer): The PyTorch Lightning trainer object.\n",
    "            pl_module (pl.LightningModule): The PyTorch Lightning module being trained.\n",
    "        \"\"\"\n",
    "        metrics = trainer.callback_metrics\n",
    "        self.validation_metrics.append(metrics)\n",
    "\n",
    "    def get_metrics_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns a Pandas DataFrame containing the collected validation metrics.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A Pandas DataFrame containing the collected validation metrics.\n",
    "        \"\"\"\n",
    "        return pd.DataFrame(self.validation_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd052843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"class EpochTimeCallback(pl.Callback):\\n    \\\"\\\"\\\"\\n    A PyTorch Lightning callback to measure and store the duration of each epoch.\\n    \\n    Attributes:\\n    epoch_times_df (pd.DataFrame): A dataframe containing epoch numbers and their corresponding durations.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self):\\n        \\\"\\\"\\\"Initializes the callback and sets up an empty dataframe to store epoch times.\\\"\\\"\\\"\\n        super().__init__()\\n        self.epoch_times_df: pd.DataFrame = pd.DataFrame(columns=['Epoch', 'Duration'])\\n\\n    def on_epoch_start(self, trainer: pl.Trainer, pl_module: pl.LightningModule) -> None:\\n        \\\"\\\"\\\"\\n        Record the start time of the epoch.\\n\\n        Args:\\n        trainer (pl.Trainer): The trainer object.\\n        pl_module (pl.LightningModule): The model/module being trained.\\n        \\\"\\\"\\\"\\n        self.epoch_start_time = time.time()\\n\\n    def on_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule) -> None:\\n        \\\"\\\"\\\"\\n        Calculate and store the duration of the epoch, and print the epoch duration.\\n\\n        Args:\\n        trainer (pl.Trainer): The trainer object.\\n        pl_module (pl.LightningModule): The model/module being trained.\\n        \\\"\\\"\\\"\\n        epoch_end_time = time.time()\\n        epoch_duration = epoch_end_time - self.epoch_start_time\\n        epoch = trainer.current_epoch + 1\\n\\n        self.epoch_times_df.loc[len(self.epoch_times_df)] = [epoch, epoch_duration]\\n        print(f\\\"Epoch {epoch} execution time: {epoch_duration:.2f} seconds\\\")\\n\\n    def get_epoch_times_df(self) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Retrieve the dataframe containing epoch durations.\\n\\n        Returns:\\n        pd.DataFrame: A dataframe containing epoch numbers and their corresponding durations.\\n        \\\"\\\"\\\"\\n        return self.epoch_times_df\";\n",
       "                var nbb_formatted_code = \"class EpochTimeCallback(pl.Callback):\\n    \\\"\\\"\\\"\\n    A PyTorch Lightning callback to measure and store the duration of each epoch.\\n\\n    Attributes:\\n    epoch_times_df (pd.DataFrame): A dataframe containing epoch numbers and their corresponding durations.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self):\\n        \\\"\\\"\\\"Initializes the callback and sets up an empty dataframe to store epoch times.\\\"\\\"\\\"\\n        super().__init__()\\n        self.epoch_times_df: pd.DataFrame = pd.DataFrame(columns=[\\\"Epoch\\\", \\\"Duration\\\"])\\n\\n    def on_epoch_start(\\n        self, trainer: pl.Trainer, pl_module: pl.LightningModule\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Record the start time of the epoch.\\n\\n        Args:\\n        trainer (pl.Trainer): The trainer object.\\n        pl_module (pl.LightningModule): The model/module being trained.\\n        \\\"\\\"\\\"\\n        self.epoch_start_time = time.time()\\n\\n    def on_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule) -> None:\\n        \\\"\\\"\\\"\\n        Calculate and store the duration of the epoch, and print the epoch duration.\\n\\n        Args:\\n        trainer (pl.Trainer): The trainer object.\\n        pl_module (pl.LightningModule): The model/module being trained.\\n        \\\"\\\"\\\"\\n        epoch_end_time = time.time()\\n        epoch_duration = epoch_end_time - self.epoch_start_time\\n        epoch = trainer.current_epoch + 1\\n\\n        self.epoch_times_df.loc[len(self.epoch_times_df)] = [epoch, epoch_duration]\\n        print(f\\\"Epoch {epoch} execution time: {epoch_duration:.2f} seconds\\\")\\n\\n    def get_epoch_times_df(self) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Retrieve the dataframe containing epoch durations.\\n\\n        Returns:\\n        pd.DataFrame: A dataframe containing epoch numbers and their corresponding durations.\\n        \\\"\\\"\\\"\\n        return self.epoch_times_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class EpochTimeCallback(pl.Callback):\n",
    "    \"\"\"\n",
    "    A PyTorch Lightning callback to measure and store the duration of each epoch.\n",
    "    \n",
    "    Attributes:\n",
    "    epoch_times_df (pd.DataFrame): A dataframe containing epoch numbers and their corresponding durations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the callback and sets up an empty dataframe to store epoch times.\"\"\"\n",
    "        super().__init__()\n",
    "        self.epoch_times_df: pd.DataFrame = pd.DataFrame(columns=['Epoch', 'Duration'])\n",
    "\n",
    "    def on_epoch_start(self, trainer: pl.Trainer, pl_module: pl.LightningModule) -> None:\n",
    "        \"\"\"\n",
    "        Record the start time of the epoch.\n",
    "\n",
    "        Args:\n",
    "        trainer (pl.Trainer): The trainer object.\n",
    "        pl_module (pl.LightningModule): The model/module being trained.\n",
    "        \"\"\"\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule) -> None:\n",
    "        \"\"\"\n",
    "        Calculate and store the duration of the epoch, and print the epoch duration.\n",
    "\n",
    "        Args:\n",
    "        trainer (pl.Trainer): The trainer object.\n",
    "        pl_module (pl.LightningModule): The model/module being trained.\n",
    "        \"\"\"\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        epoch = trainer.current_epoch + 1\n",
    "\n",
    "        self.epoch_times_df.loc[len(self.epoch_times_df)] = [epoch, epoch_duration]\n",
    "        print(f\"Epoch {epoch} execution time: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "    def get_epoch_times_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieve the dataframe containing epoch durations.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A dataframe containing epoch numbers and their corresponding durations.\n",
    "        \"\"\"\n",
    "        return self.epoch_times_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c8867b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"log_collector = ValidationLogCollectorCallback()\";\n",
       "                var nbb_formatted_code = \"log_collector = ValidationLogCollectorCallback()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_collector = ValidationLogCollectorCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20ffd86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"epoch_time_callback = EpochTimeCallback()\";\n",
       "                var nbb_formatted_code = \"epoch_time_callback = EpochTimeCallback()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_time_callback = EpochTimeCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6327d",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade9708",
   "metadata": {},
   "source": [
    "The metrics of each models as well as time used for training and prediction were recorded into a dictionary which will be later transformed into a pandas dataframe in order to compare scores of various models. Initially, the structure of the dictionary was set that was latter filled with the appended data from the steps of training, model assessment and predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c87148a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"metrics_df = {}\\nmetrics_df[\\\"model_name\\\"] = []\\nmetrics_df[\\\"train_time\\\"] = []\\nmetrics_df[\\\"tune_time\\\"] = []\\nmetrics_df[\\\"prediction_time_trained\\\"] = []\\nmetrics_df[\\\"prediction_time_tuned\\\"] = []\\nmetrics_df[\\\"train_loss_trained\\\"] = []\\nmetrics_df[\\\"train_loss_tuned\\\"] = []\\nmetrics_df[\\\"val_loss_trained\\\"] = []\\nmetrics_df[\\\"val_loss_tuned\\\"] = []\";\n",
       "                var nbb_formatted_code = \"metrics_df = {}\\nmetrics_df[\\\"model_name\\\"] = []\\nmetrics_df[\\\"train_time\\\"] = []\\nmetrics_df[\\\"tune_time\\\"] = []\\nmetrics_df[\\\"prediction_time_trained\\\"] = []\\nmetrics_df[\\\"prediction_time_tuned\\\"] = []\\nmetrics_df[\\\"train_loss_trained\\\"] = []\\nmetrics_df[\\\"train_loss_tuned\\\"] = []\\nmetrics_df[\\\"val_loss_trained\\\"] = []\\nmetrics_df[\\\"val_loss_tuned\\\"] = []\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_df = {}\n",
    "metrics_df[\"model_name\"] = []\n",
    "metrics_df[\"train_time\"] = []\n",
    "metrics_df[\"tune_time\"] = []\n",
    "metrics_df[\"prediction_time_trained\"] = []\n",
    "metrics_df[\"prediction_time_tuned\"] = []\n",
    "metrics_df[\"train_loss_trained\"] = []\n",
    "metrics_df[\"train_loss_tuned\"] = []\n",
    "metrics_df[\"val_loss_trained\"] = []\n",
    "metrics_df[\"val_loss_tuned\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b745e",
   "metadata": {},
   "source": [
    "The model is trained with the Pytorch Lighntning trainer and, after the training process ended, is got saved into a local file. Data on the total training time is saved in the dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fdf803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type                                | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | distilbert | DistilBertForSequenceClassification | 67.0 M\n",
      "-------------------------------------------------------------------\n",
      "592 K     Trainable params\n",
      "66.4 M    Non-trainable params\n",
      "67.0 M    Total params\n",
      "267.820   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b47852e8c064e65b02dedd55a70a3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model_name: Distilbert\n",
      "Execution time: 0.44870544300358667\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"\\nstart_time = time.time()\\ntrainer = pl.Trainer(\\n    max_epochs=10,\\n    logger=tensorboard_logger,\\n    callbacks=[\\n        checkpoint_callback,\\n        log_collector,\\n        early_stopping_callback,\\n        epoch_time_callback,\\n    ],\\n)\\ntrainer.fit(\\n    model\\n    #ckpt_path=last_checkpoint_path\\n)\\n#trainer_list.append(trainer)\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(train_dataset)\\nprint(\\\"\\\")\\nprint(f\\\"Model_name: Distilbert\\\")\\nprint(f\\\"Execution time: {exec_time}\\\")\\nmetrics_df[\\\"model_name\\\"].append(\\\"Distilbert\\\")\\nmetrics_df[\\\"train_time\\\"].append(exec_time)\\ncheckpoint_path = f\\\"models/model_trained_Distilbert2.ckpt\\\"\\ntrainer.save_checkpoint(checkpoint_path)\";\n",
       "                var nbb_formatted_code = \"start_time = time.time()\\ntrainer = pl.Trainer(\\n    max_epochs=10,\\n    logger=tensorboard_logger,\\n    callbacks=[\\n        checkpoint_callback,\\n        log_collector,\\n        early_stopping_callback,\\n        epoch_time_callback,\\n    ],\\n)\\ntrainer.fit(\\n    model\\n    # ckpt_path=last_checkpoint_path\\n)\\n# trainer_list.append(trainer)\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(train_dataset)\\nprint(\\\"\\\")\\nprint(f\\\"Model_name: Distilbert\\\")\\nprint(f\\\"Execution time: {exec_time}\\\")\\nmetrics_df[\\\"model_name\\\"].append(\\\"Distilbert\\\")\\nmetrics_df[\\\"train_time\\\"].append(exec_time)\\ncheckpoint_path = f\\\"models/model_trained_Distilbert2.ckpt\\\"\\ntrainer.save_checkpoint(checkpoint_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    logger=tensorboard_logger,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        log_collector,\n",
    "        early_stopping_callback,\n",
    "        epoch_time_callback,\n",
    "    ],\n",
    ")\n",
    "trainer.fit(\n",
    "    model\n",
    "    #ckpt_path=last_checkpoint_path\n",
    ")\n",
    "#trainer_list.append(trainer)\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) / len(train_dataset)\n",
    "print(\"\")\n",
    "print(f\"Model_name: Distilbert\")\n",
    "print(f\"Execution time: {exec_time}\")\n",
    "metrics_df[\"model_name\"].append(\"Distilbert\")\n",
    "metrics_df[\"train_time\"].append(exec_time)\n",
    "checkpoint_path = f\"models/model_trained_Distilbert2.ckpt\"\n",
    "trainer.save_checkpoint(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3f91f",
   "metadata": {},
   "source": [
    "The training of the models with many layers freezed was conducted for maximum ten epochs, however, it was interupted by early stopping callback after 4 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f89c2da",
   "metadata": {},
   "source": [
    "### Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358f787",
   "metadata": {},
   "source": [
    "The next step is to fine-tune the model - that is, to calculate gradients by comparing predicted outputs with label data and adjust weights accordingly. \n",
    "\n",
    "First, the trained model is loaded from the local checkpoint path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f54d0",
   "metadata": {},
   "source": [
    "Bert_grad parameter is set to True in order to allow calculation os gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d284f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized because the shapes did not match:\n",
      "- distilbert.embeddings.word_embeddings.weight: found shape torch.Size([28996, 768]) in the checkpoint and torch.Size([30522, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type                                | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | distilbert | DistilBertForSequenceClassification | 67.0 M\n",
      "-------------------------------------------------------------------\n",
      "67.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "67.0 M    Total params\n",
      "267.820   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3833f95c7dc6468db04fa511618664d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model_name: Distilbert\n",
      "Execution time: 0.5045651809244832\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"last_checkpoint_path = f\\\"models/model_trained_Distilbert2.ckpt\\\"\\n\\nmodel = FakeNewsModelDistilbert.load_from_checkpoint(\\n    checkpoint_path=last_checkpoint_path,\\n    batch_size=batch_size,\\n    num_classes=2,\\n    model=\\\"Distilbert\\\",\\n    lr=0.0001,\\n)\\n\\ndevice = torch.device(\\\"mps\\\")\\nmodel.to(device)\\n\\nmodel.distilbert_grad(True)\\n\\nstart_time = time.time()\\ntrainer = pl.Trainer(\\n    max_epochs=30,\\n    logger=tensorboard_logger,\\n    callbacks=[\\n        checkpoint_callback,\\n        log_collector,\\n        early_stopping_callback,\\n        epoch_time_callback,\\n    ],\\n)\\ntrainer.fit(\\n    model,\\n    DataLoader(train_dataset, batch_size),\\n    # ckpt_path=last_checkpoint_path\\n)\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(train_dataset)\\nprint(\\\"\\\")\\nprint(f\\\"Model_name: Distilbert\\\")\\nprint(f\\\"Execution time: {exec_time}\\\")\\nmetrics_df[\\\"tune_time\\\"].append(exec_time)\\ncheckpoint_path = f\\\"models/model_tuned_Distilbert.ckpt\\\"\\ntrainer.save_checkpoint(checkpoint_path)\";\n",
       "                var nbb_formatted_code = \"last_checkpoint_path = f\\\"models/model_trained_Distilbert2.ckpt\\\"\\n\\nmodel = FakeNewsModelDistilbert.load_from_checkpoint(\\n    checkpoint_path=last_checkpoint_path,\\n    batch_size=batch_size,\\n    num_classes=2,\\n    model=\\\"Distilbert\\\",\\n    lr=0.0001,\\n)\\n\\ndevice = torch.device(\\\"mps\\\")\\nmodel.to(device)\\n\\nmodel.distilbert_grad(True)\\n\\nstart_time = time.time()\\ntrainer = pl.Trainer(\\n    max_epochs=30,\\n    logger=tensorboard_logger,\\n    callbacks=[\\n        checkpoint_callback,\\n        log_collector,\\n        early_stopping_callback,\\n        epoch_time_callback,\\n    ],\\n)\\ntrainer.fit(\\n    model,\\n    DataLoader(train_dataset, batch_size),\\n    # ckpt_path=last_checkpoint_path\\n)\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(train_dataset)\\nprint(\\\"\\\")\\nprint(f\\\"Model_name: Distilbert\\\")\\nprint(f\\\"Execution time: {exec_time}\\\")\\nmetrics_df[\\\"tune_time\\\"].append(exec_time)\\ncheckpoint_path = f\\\"models/model_tuned_Distilbert.ckpt\\\"\\ntrainer.save_checkpoint(checkpoint_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_checkpoint_path = f\"models/model_trained_Distilbert2.ckpt\"\n",
    "\n",
    "model = FakeNewsModelDistilbert.load_from_checkpoint(\n",
    "    checkpoint_path=last_checkpoint_path,\n",
    "    batch_size=batch_size,\n",
    "    num_classes=2,\n",
    "    model=\"Distilbert\",\n",
    "    lr=0.0001,\n",
    ")\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "\n",
    "model.distilbert_grad(True)\n",
    "\n",
    "start_time = time.time()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    logger=tensorboard_logger,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        log_collector,\n",
    "        early_stopping_callback,\n",
    "        epoch_time_callback,\n",
    "    ],\n",
    ")\n",
    "trainer.fit(\n",
    "    model,\n",
    "    DataLoader(train_dataset, batch_size),\n",
    "    # ckpt_path=last_checkpoint_path\n",
    ")\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) / len(train_dataset)\n",
    "print(\"\")\n",
    "print(f\"Model_name: Distilbert\")\n",
    "print(f\"Execution time: {exec_time}\")\n",
    "metrics_df[\"tune_time\"].append(exec_time)\n",
    "checkpoint_path = f\"models/model_tuned_Distilbert.ckpt\"\n",
    "trainer.save_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce67ff7-be9e-467a-9ade-ec68f3293877",
   "metadata": {},
   "source": [
    "The fine-tuning of the model stopped after 3 epochs (though maximum 30 epochs were set). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe843c",
   "metadata": {},
   "source": [
    "### Predictions on the trained model and validation and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4380448",
   "metadata": {},
   "source": [
    "Next, predictions on the fine-tuned model were generated. The model was loaded from the checkpoint path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b270444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized because the shapes did not match:\n",
      "- distilbert.embeddings.word_embeddings.weight: found shape torch.Size([28996, 768]) in the checkpoint and torch.Size([30522, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"checkpoint_path = f\\\"models/model_trained_Distilbert2.ckpt\\\"\\nmodel = FakeNewsModelDistilbert.load_from_checkpoint(\\n    checkpoint_path=checkpoint_path,\\n    batch_size=batch_size,\\n    num_classes=2,\\n    model=\\\"Distilbert\\\",\\n    lr=0.001,\\n)\";\n",
       "                var nbb_formatted_code = \"checkpoint_path = f\\\"models/model_trained_Distilbert2.ckpt\\\"\\nmodel = FakeNewsModelDistilbert.load_from_checkpoint(\\n    checkpoint_path=checkpoint_path,\\n    batch_size=batch_size,\\n    num_classes=2,\\n    model=\\\"Distilbert\\\",\\n    lr=0.001,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_path = f\"models/model_trained_Distilbert2.ckpt\"\n",
    "model = FakeNewsModelDistilbert.load_from_checkpoint(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    batch_size=batch_size,\n",
    "    num_classes=2,\n",
    "    model=\"Distilbert\",\n",
    "    lr=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07678e9b",
   "metadata": {},
   "source": [
    "The GPU processor is attached to models, sample weights, and to the eval() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1eda6ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"device = torch.device(\\\"mps\\\")\\nmodel.to(device)\\nmodel = model.eval().to(device)\";\n",
       "                var nbb_formatted_code = \"device = torch.device(\\\"mps\\\")\\nmodel.to(device)\\nmodel = model.eval().to(device)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "model = model.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b117d4",
   "metadata": {},
   "source": [
    "For the prediction, data is loaded from the validation dataset with the validation loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d14b70d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"val_loader = DataLoader(\\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n)\\ntest_loader = DataLoader(\\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n)\";\n",
       "                var nbb_formatted_code = \"val_loader = DataLoader(\\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n)\\ntest_loader = DataLoader(\\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=3\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd338811-75b2-4ff3-a38d-788c833e93dc",
   "metadata": {},
   "source": [
    "#### Validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b5ead1",
   "metadata": {},
   "source": [
    "Predictions are generated on the trained model and the fine-tuned model and saved into the list. Trues values are also set to a list as well as losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "562527de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.021700182087975414\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"y_val_pred_trained = []\\ny_true_trained = []\\nlosses_trained = []\\nsigmoids_list_trained = []\\nstart_time = time.time()\\nwith torch.no_grad():\\n    for i, batch in enumerate(val_loader):\\n        batch = {k: v.to(device) for k, v in batch.items()}\\n        loss, outputs = model(**batch)\\n        sigmoids = torch.sigmoid(outputs)\\n        preds = (sigmoids > 0.5).to(torch.int)\\n        y_val_pred_trained += preds.tolist()\\n        y_true_trained += batch[\\\"labels\\\"].tolist()\\n        sigmoids_list_trained.append(sigmoids)\\n        losses_trained.append(loss.item())\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(val_dataset)\\n\\nprint(f\\\"Prediction time: {exec_time}\\\")\";\n",
       "                var nbb_formatted_code = \"y_val_pred_trained = []\\ny_true_trained = []\\nlosses_trained = []\\nsigmoids_list_trained = []\\nstart_time = time.time()\\nwith torch.no_grad():\\n    for i, batch in enumerate(val_loader):\\n        batch = {k: v.to(device) for k, v in batch.items()}\\n        loss, outputs = model(**batch)\\n        sigmoids = torch.sigmoid(outputs)\\n        preds = (sigmoids > 0.5).to(torch.int)\\n        y_val_pred_trained += preds.tolist()\\n        y_true_trained += batch[\\\"labels\\\"].tolist()\\n        sigmoids_list_trained.append(sigmoids)\\n        losses_trained.append(loss.item())\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(val_dataset)\\n\\nprint(f\\\"Prediction time: {exec_time}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_val_pred_trained = []\n",
    "y_true_trained = []\n",
    "losses_trained = []\n",
    "sigmoids_list_trained = []\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, outputs = model(**batch)\n",
    "        sigmoids = torch.sigmoid(outputs)\n",
    "        preds = (sigmoids > 0.5).to(torch.int)\n",
    "        y_val_pred_trained += preds.tolist()\n",
    "        y_true_trained += batch[\"labels\"].tolist()\n",
    "        sigmoids_list_trained.append(sigmoids)\n",
    "        losses_trained.append(loss.item())\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) / len(val_dataset)\n",
    "\n",
    "print(f\"Prediction time: {exec_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1f8bc9",
   "metadata": {},
   "source": [
    "The mean of losses of from all prediction values is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "826dbb8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation loss for the trained model: 0.6058896740935826\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"val_loss_trained = np.mean(losses_trained)\\nmetrics_df[\\\"val_loss_trained\\\"].append(val_loss_trained)\\nprint(\\\"Mean validation loss for the trained model:\\\", val_loss_trained)\";\n",
       "                var nbb_formatted_code = \"val_loss_trained = np.mean(losses_trained)\\nmetrics_df[\\\"val_loss_trained\\\"].append(val_loss_trained)\\nprint(\\\"Mean validation loss for the trained model:\\\", val_loss_trained)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss_trained = np.mean(losses_trained)\n",
    "metrics_df[\"val_loss_trained\"].append(val_loss_trained)\n",
    "print(\"Mean validation loss for the trained model:\", val_loss_trained)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df26862-3ce1-4b47-8847-a0ad988b6ae5",
   "metadata": {},
   "source": [
    "#### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae26f126-3920-4fdf-8a2b-789d0627749c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.021973901522451624\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"y_test_pred_trained = []\\ny_true_trained_test = []\\nlosses_trained_test = []\\nlosses_trained_test = []\\nsigmoids_list_trained_test = []\\nstart_time = time.time()\\nwith torch.no_grad():\\n    for i, batch in enumerate(test_loader):\\n        batch = {k: v.to(device) for k, v in batch.items()}\\n        loss, outputs = model(**batch)\\n        sigmoids = torch.sigmoid(outputs)\\n        preds = (sigmoids > 0.5).to(torch.int)\\n        y_test_pred_trained += preds.tolist()\\n        y_true_trained_test += batch[\\\"labels\\\"].tolist()\\n        sigmoids_list_trained_test.append(sigmoids)\\n        losses_trained_test.append(loss.item())\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(test_dataset)\\n\\nprint(f\\\"Prediction time: {exec_time}\\\")\";\n",
       "                var nbb_formatted_code = \"y_test_pred_trained = []\\ny_true_trained_test = []\\nlosses_trained_test = []\\nlosses_trained_test = []\\nsigmoids_list_trained_test = []\\nstart_time = time.time()\\nwith torch.no_grad():\\n    for i, batch in enumerate(test_loader):\\n        batch = {k: v.to(device) for k, v in batch.items()}\\n        loss, outputs = model(**batch)\\n        sigmoids = torch.sigmoid(outputs)\\n        preds = (sigmoids > 0.5).to(torch.int)\\n        y_test_pred_trained += preds.tolist()\\n        y_true_trained_test += batch[\\\"labels\\\"].tolist()\\n        sigmoids_list_trained_test.append(sigmoids)\\n        losses_trained_test.append(loss.item())\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(test_dataset)\\n\\nprint(f\\\"Prediction time: {exec_time}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_pred_trained = []\n",
    "y_true_trained_test = []\n",
    "losses_trained_test = []\n",
    "sigmoids_list_trained_test = []\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, outputs = model(**batch)\n",
    "        sigmoids = torch.sigmoid(outputs)\n",
    "        preds = (sigmoids > 0.5).to(torch.int)\n",
    "        y_test_pred_trained += preds.tolist()\n",
    "        y_true_trained_test += batch[\"labels\"].tolist()\n",
    "        sigmoids_list_trained_test.append(sigmoids)\n",
    "        losses_trained_test.append(loss.item())\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) / len(test_dataset)\n",
    "\n",
    "print(f\"Prediction time: {exec_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "351d23f7-b121-4329-bd25-30c34277bd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test loss for the tuned model: 0.6062753168339188\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"test_loss_trained = np.mean(losses_trained_test)\\nprint(\\\"Mean test loss for the tuned model:\\\", test_loss_trained)\";\n",
       "                var nbb_formatted_code = \"test_loss_trained = np.mean(losses_trained_test)\\nprint(\\\"Mean test loss for the tuned model:\\\", test_loss_trained)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loss_trained = np.mean(losses_trained_test)\n",
    "print(\"Mean test loss for the tuned model:\", test_loss_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96957f91-a877-4573-aac4-13df54e859fc",
   "metadata": {},
   "source": [
    "### Predictions on the fine-tuned model and validation and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d74ddf-637e-4df6-8254-bf8e5a5cf372",
   "metadata": {},
   "source": [
    "Next, predictions on the fine-tuned model were generated. The model was loaded from the checkpoint path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1066825-7313-466d-a020-f2ab43ceaf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized because the shapes did not match:\n",
      "- distilbert.embeddings.word_embeddings.weight: found shape torch.Size([28996, 768]) in the checkpoint and torch.Size([30522, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"checkpoint_path = f\\\"models/model_tuned_Distilbert.ckpt\\\"\\nmodel2 = FakeNewsModelDistilbert.load_from_checkpoint(\\n    checkpoint_path=checkpoint_path,\\n    batch_size=batch_size,\\n    num_classes=2,\\n    model=\\\"Distilbert\\\",\\n    lr=0.0001,\\n)\";\n",
       "                var nbb_formatted_code = \"checkpoint_path = f\\\"models/model_tuned_Distilbert.ckpt\\\"\\nmodel2 = FakeNewsModelDistilbert.load_from_checkpoint(\\n    checkpoint_path=checkpoint_path,\\n    batch_size=batch_size,\\n    num_classes=2,\\n    model=\\\"Distilbert\\\",\\n    lr=0.0001,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_path = f\"models/model_tuned_Distilbert.ckpt\"\n",
    "model2 = FakeNewsModelDistilbert.load_from_checkpoint(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    batch_size=batch_size,\n",
    "    num_classes=2,\n",
    "    model=\"Distilbert\",\n",
    "    lr=0.0001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311cc71-fd96-47d5-8b44-8cde6e4766c9",
   "metadata": {},
   "source": [
    "The GPU processor is attached to models, sample weights, and to the eval() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f610abd2-1efd-40a8-ac76-a0434e90651a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"device = torch.device(\\\"mps\\\")\\nmodel2.to(device)\\nmodel2 = model2.eval().to(device)\";\n",
       "                var nbb_formatted_code = \"device = torch.device(\\\"mps\\\")\\nmodel2.to(device)\\nmodel2 = model2.eval().to(device)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "model2.to(device)\n",
    "model2 = model2.eval().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e02b44-0335-4872-897b-3d49fed6622e",
   "metadata": {},
   "source": [
    "For the prediction, data is loaded from the validation dataset with the validation loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cddd4e81-2827-4c15-b7a5-de8ded196b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"val_loader = DataLoader(\\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n)\\ntest_loader = DataLoader(\\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n)\";\n",
       "                var nbb_formatted_code = \"val_loader = DataLoader(\\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n)\\ntest_loader = DataLoader(\\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=3\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=3\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e8ee00-dc2f-45cd-b173-3a2350ad278a",
   "metadata": {},
   "source": [
    "#### Validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d76127-5ea3-457c-8924-c9cc58430847",
   "metadata": {},
   "source": [
    "Predictions are generated on the trained model and the fine-tuned model and saved into the list. Trues values are also set to a list as well as losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c364ed6-5a3f-4959-bc20-6c18f2edb081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.02203211390605064\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"y_val_pred_tuned = []\\ny_true_tuned = []\\nlosses_tuned = []\\nsigmoids_list_tuned = []\\nstart_time = time.time()\\nwith torch.no_grad():\\n    for i, batch in enumerate(val_loader):\\n        batch = {k: v.to(device) for k, v in batch.items()}\\n        loss, outputs = model2(**batch)\\n        sigmoids = torch.sigmoid(outputs)\\n        preds = (sigmoids > 0.6).to(torch.int)\\n        y_val_pred_tuned += preds.tolist()\\n        y_true_tuned += batch[\\\"labels\\\"].tolist()\\n        sigmoids_list_tuned.append(sigmoids)\\n        losses_tuned.append(loss.item())\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(val_dataset)\\n\\nprint(f\\\"Prediction time: {exec_time}\\\")\";\n",
       "                var nbb_formatted_code = \"y_val_pred_tuned = []\\ny_true_tuned = []\\nlosses_tuned = []\\nsigmoids_list_tuned = []\\nstart_time = time.time()\\nwith torch.no_grad():\\n    for i, batch in enumerate(val_loader):\\n        batch = {k: v.to(device) for k, v in batch.items()}\\n        loss, outputs = model2(**batch)\\n        sigmoids = torch.sigmoid(outputs)\\n        preds = (sigmoids > 0.6).to(torch.int)\\n        y_val_pred_tuned += preds.tolist()\\n        y_true_tuned += batch[\\\"labels\\\"].tolist()\\n        sigmoids_list_tuned.append(sigmoids)\\n        losses_tuned.append(loss.item())\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(val_dataset)\\n\\nprint(f\\\"Prediction time: {exec_time}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_val_pred_tuned = []\n",
    "y_true_tuned = []\n",
    "losses_tuned = []\n",
    "sigmoids_list_tuned = []\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, outputs = model2(**batch)\n",
    "        sigmoids = torch.sigmoid(outputs)\n",
    "        preds = (sigmoids > 0.5).to(torch.int)\n",
    "        y_val_pred_tuned += preds.tolist()\n",
    "        y_true_tuned += batch[\"labels\"].tolist()\n",
    "        sigmoids_list_tuned.append(sigmoids)\n",
    "        losses_tuned.append(loss.item())\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) / len(val_dataset)\n",
    "\n",
    "print(f\"Prediction time: {exec_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f605131-b137-4bcf-a38f-86afa4848994",
   "metadata": {},
   "source": [
    "The mean of losses of from all prediction values is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "848f6c1d-c989-4f2a-91b0-25a99a258c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation loss for the tuned model: 0.03285893765925056\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"val_loss_tuned = np.mean(losses_tuned)\\nmetrics_df[\\\"val_loss_tuned\\\"].append(val_loss_tuned)\\nprint(\\\"Mean validation loss for the tuned model:\\\", val_loss_tuned)\";\n",
       "                var nbb_formatted_code = \"val_loss_tuned = np.mean(losses_tuned)\\nmetrics_df[\\\"val_loss_tuned\\\"].append(val_loss_tuned)\\nprint(\\\"Mean validation loss for the tuned model:\\\", val_loss_tuned)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss_tuned = np.mean(losses_tuned)\n",
    "metrics_df[\"val_loss_tuned\"].append(val_loss_tuned)\n",
    "print(\"Mean validation loss for the tuned model:\", val_loss_tuned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70593251-75b9-41e6-949f-b8fc201e724a",
   "metadata": {},
   "source": [
    "#### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24d1be46-722c-4d31-a4eb-2012861a4515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 0.025482823508884964\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"y_test_pred_tuned = []\\ny_true_tuned_test = []\\nlosses_tuned_test = []\\nlosses_tuned_test = []\\nsigmoids_list_tuned_test = []\\nstart_time = time.time()\\nwith torch.no_grad():\\n    for i, batch in enumerate(test_loader):\\n        batch = {k: v.to(device) for k, v in batch.items()}\\n        loss, outputs = model2(**batch)\\n        sigmoids = torch.sigmoid(outputs)\\n        preds = (sigmoids > 0.5).to(torch.int)\\n        y_test_pred_tuned += preds.tolist()\\n        y_true_tuned_test += batch[\\\"labels\\\"].tolist()\\n        sigmoids_list_tuned_test.append(sigmoids)\\n        losses_tuned_test.append(loss.item())\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(test_dataset)\\n\\nprint(f\\\"Prediction time: {exec_time}\\\")\";\n",
       "                var nbb_formatted_code = \"y_test_pred_tuned = []\\ny_true_tuned_test = []\\nlosses_tuned_test = []\\nlosses_tuned_test = []\\nsigmoids_list_tuned_test = []\\nstart_time = time.time()\\nwith torch.no_grad():\\n    for i, batch in enumerate(test_loader):\\n        batch = {k: v.to(device) for k, v in batch.items()}\\n        loss, outputs = model2(**batch)\\n        sigmoids = torch.sigmoid(outputs)\\n        preds = (sigmoids > 0.5).to(torch.int)\\n        y_test_pred_tuned += preds.tolist()\\n        y_true_tuned_test += batch[\\\"labels\\\"].tolist()\\n        sigmoids_list_tuned_test.append(sigmoids)\\n        losses_tuned_test.append(loss.item())\\nend_time = time.time()\\nexec_time = (end_time - start_time) / len(test_dataset)\\n\\nprint(f\\\"Prediction time: {exec_time}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_pred_tuned = []\n",
    "y_true_tuned_test = []\n",
    "losses_tuned_test = []\n",
    "sigmoids_list_tuned_test = []\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, outputs = model2(**batch)\n",
    "        sigmoids = torch.sigmoid(outputs)\n",
    "        preds = (sigmoids > 0.5).to(torch.int)\n",
    "        y_test_pred_tuned += preds.tolist()\n",
    "        y_true_tuned_test += batch[\"labels\"].tolist()\n",
    "        sigmoids_list_tuned_test.append(sigmoids)\n",
    "        losses_tuned_test.append(loss.item())\n",
    "end_time = time.time()\n",
    "exec_time = (end_time - start_time) / len(test_dataset)\n",
    "\n",
    "print(f\"Prediction time: {exec_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b98b49de-8459-4f6a-9c77-90620cea6cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test loss for the tuned model: 0.025447170999816894\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"test_loss_tuned = np.mean(losses_tuned_test)\\nprint(\\\"Mean test loss for the tuned model:\\\", test_loss_tuned)\";\n",
       "                var nbb_formatted_code = \"test_loss_tuned = np.mean(losses_tuned_test)\\nprint(\\\"Mean test loss for the tuned model:\\\", test_loss_tuned)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loss_tuned = np.mean(losses_tuned_test)\n",
    "print(\"Mean test loss for the tuned model:\", test_loss_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215d04a",
   "metadata": {},
   "source": [
    "The dictionary with the added validation and test metrics was saved to the local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c77809b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary saved to a file.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"with open(\\\"metrics_df.pkl\\\", \\\"wb\\\") as fp:\\n    pickle.dump(metrics_df, fp)\\n    print(\\\"The dictionary saved to a file.\\\")\";\n",
       "                var nbb_formatted_code = \"with open(\\\"metrics_df.pkl\\\", \\\"wb\\\") as fp:\\n    pickle.dump(metrics_df, fp)\\n    print(\\\"The dictionary saved to a file.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"metrics_df.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(metrics_df, fp)\n",
    "    print(\"The dictionary saved to a file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f4893-9a24-43f0-a460-d732bf05a912",
   "metadata": {},
   "source": [
    "## Assessments of trained and fine-tuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a59f5",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168e7af",
   "metadata": {},
   "source": [
    "Based on values which were generated from running the models on validation data, confusion matrixes are created and presented as heatmaps bellow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89d92f6e-c824-47bc-9972-dd92c09ed4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 74;\n",
       "                var nbb_unformatted_code = \"y_val_pred_trained2 = [sublist[1] for sublist in y_val_pred_trained]\\ny_test_pred_trained2 = [sublist[1] for sublist in y_test_pred_trained]\\n\\ny_val_pred_tuned2 = [sublist[1] for sublist in y_val_pred_tuned]\\ny_test_pred_tuned2 = [sublist[1] for sublist in y_test_pred_tuned]\";\n",
       "                var nbb_formatted_code = \"y_val_pred_trained2 = [sublist[1] for sublist in y_val_pred_trained]\\ny_test_pred_trained2 = [sublist[1] for sublist in y_test_pred_trained]\\n\\ny_val_pred_tuned2 = [sublist[1] for sublist in y_val_pred_tuned]\\ny_test_pred_tuned2 = [sublist[1] for sublist in y_test_pred_tuned]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_val_pred_trained2 = [sublist[1] for sublist in y_val_pred_trained]\n",
    "y_test_pred_trained2 = [sublist[1] for sublist in y_test_pred_trained]\n",
    "\n",
    "y_val_pred_tuned2 = [sublist[1] for sublist in y_val_pred_tuned]\n",
    "y_test_pred_tuned2 = [sublist[1] for sublist in y_test_pred_tuned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c40913a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 75;\n",
       "                var nbb_unformatted_code = \"conf_mat_trained = confusion_matrix(y_true_trained, y_val_pred_trained2)\\nconf_mat_trained_test = confusion_matrix(y_true_trained_test, y_test_pred_trained2)\\n\\nconf_mat_tuned = confusion_matrix(y_true_tuned, y_val_pred_tuned2)\\nconf_mat_tuned_test = confusion_matrix(y_true_tuned_test, y_test_pred_tuned2)\";\n",
       "                var nbb_formatted_code = \"conf_mat_trained = confusion_matrix(y_true_trained, y_val_pred_trained2)\\nconf_mat_trained_test = confusion_matrix(y_true_trained_test, y_test_pred_trained2)\\n\\nconf_mat_tuned = confusion_matrix(y_true_tuned, y_val_pred_tuned2)\\nconf_mat_tuned_test = confusion_matrix(y_true_tuned_test, y_test_pred_tuned2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat_trained = confusion_matrix(y_true_trained, y_val_pred_trained2)\n",
    "conf_mat_trained_test = confusion_matrix(y_true_trained_test, y_test_pred_trained2)\n",
    "\n",
    "conf_mat_tuned = confusion_matrix(y_true_tuned, y_val_pred_tuned2)\n",
    "conf_mat_tuned_test = confusion_matrix(y_true_tuned_test, y_test_pred_tuned2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab02d6b-3e7f-440b-992a-2c15a3a6f30a",
   "metadata": {},
   "source": [
    "#### Assessments of the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ca368-5e28-48f6-8a32-ac362e595f03",
   "metadata": {},
   "source": [
    "##### Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "20078d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 66;\n",
       "                var nbb_unformatted_code = \"plt.figure(figsize=(5, 4))\\nsns.heatmap(conf_mat_trained, annot=True, fmt=\\\"d\\\", cmap=\\\"Blues\\\", cbar=False)\\nclasses = [\\\"True News\\\", \\\"Fake News\\\"]\\nplt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.title(\\\"Confusion Matrix\\\")\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"plt.figure(figsize=(5, 4))\\nsns.heatmap(conf_mat_trained, annot=True, fmt=\\\"d\\\", cmap=\\\"Blues\\\", cbar=False)\\nclasses = [\\\"True News\\\", \\\"Fake News\\\"]\\nplt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.title(\\\"Confusion Matrix\\\")\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_mat_trained, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "classes = [\"True News\", \"Fake News\"]\n",
    "plt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\n",
    "plt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01152f89-acb0-4125-9922-338bbe307e5d",
   "metadata": {},
   "source": [
    "##### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e501000a-90b4-47f0-97eb-8ecdd942c3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 67;\n",
       "                var nbb_unformatted_code = \"plt.figure(figsize=(5, 4))\\nsns.heatmap(conf_mat_trained_test, annot=True, fmt=\\\"d\\\", cmap=\\\"Blues\\\", cbar=False)\\nclasses = [\\\"True News\\\", \\\"Fake News\\\"]\\nplt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.title(\\\"Confusion Matrix\\\")\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"plt.figure(figsize=(5, 4))\\nsns.heatmap(conf_mat_trained_test, annot=True, fmt=\\\"d\\\", cmap=\\\"Blues\\\", cbar=False)\\nclasses = [\\\"True News\\\", \\\"Fake News\\\"]\\nplt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.title(\\\"Confusion Matrix\\\")\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_mat_trained_test, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "classes = [\"True News\", \"Fake News\"]\n",
    "plt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\n",
    "plt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f5123-4c5c-4969-b14c-e939165c390c",
   "metadata": {},
   "source": [
    "#### Assessments of the fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0681e2-4a41-489e-bda0-fc5ce47fbd05",
   "metadata": {},
   "source": [
    "##### Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2732e44d-0c02-40e9-bbc9-563d9fd64aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 68;\n",
       "                var nbb_unformatted_code = \"plt.figure(figsize=(5, 4))\\nsns.heatmap(conf_mat_tuned, annot=True, fmt=\\\"d\\\", cmap=\\\"Blues\\\", cbar=False)\\nclasses = [\\\"True News\\\", \\\"Fake News\\\"]\\nplt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.title(\\\"Confusion Matrix\\\")\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"plt.figure(figsize=(5, 4))\\nsns.heatmap(conf_mat_tuned, annot=True, fmt=\\\"d\\\", cmap=\\\"Blues\\\", cbar=False)\\nclasses = [\\\"True News\\\", \\\"Fake News\\\"]\\nplt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.title(\\\"Confusion Matrix\\\")\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_mat_tuned, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "classes = [\"True News\", \"Fake News\"]\n",
    "plt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\n",
    "plt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2e102f-24aa-4ab9-8e5f-309127ff385a",
   "metadata": {},
   "source": [
    "##### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6ddb6d3-7533-4120-93e6-8c86ea03ce91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 69;\n",
       "                var nbb_unformatted_code = \"plt.figure(figsize=(5, 4))\\nsns.heatmap(conf_mat_tuned_test, annot=True, fmt=\\\"d\\\", cmap=\\\"Blues\\\", cbar=False)\\nclasses = [\\\"True News\\\", \\\"Fake News\\\"]\\nplt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.title(\\\"Confusion Matrix\\\")\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"plt.figure(figsize=(5, 4))\\nsns.heatmap(conf_mat_tuned_test, annot=True, fmt=\\\"d\\\", cmap=\\\"Blues\\\", cbar=False)\\nclasses = [\\\"True News\\\", \\\"Fake News\\\"]\\nplt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\\nplt.title(\\\"Confusion Matrix\\\")\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_mat_tuned_test, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "classes = [\"True News\", \"Fake News\"]\n",
    "plt.xticks(ticks=np.arange(2) + 0.5, labels=classes)\n",
    "plt.yticks(ticks=np.arange(2) + 0.5, labels=classes)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784fb5e",
   "metadata": {},
   "source": [
    "### Classification reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15e4bc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessments of the trained model:\n",
      "\n",
      "Validation dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   True News       0.99      0.24      0.38      8600\n",
      "   Fake News       0.59      1.00      0.74      9359\n",
      "\n",
      "    accuracy                           0.63     17959\n",
      "   macro avg       0.79      0.62      0.56     17959\n",
      "weighted avg       0.78      0.63      0.57     17959\n",
      "\n",
      "Test dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   True News       0.98      0.23      0.37      4247\n",
      "   Fake News       0.59      1.00      0.74      4733\n",
      "\n",
      "    accuracy                           0.63      8980\n",
      "   macro avg       0.79      0.61      0.56      8980\n",
      "weighted avg       0.78      0.63      0.57      8980\n",
      "\n",
      "\n",
      "Assessments of the fine-tuned model:\n",
      "\n",
      "Validation dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   True News       0.99      1.00      0.99      8600\n",
      "   Fake News       1.00      0.99      0.99      9359\n",
      "\n",
      "    accuracy                           0.99     17959\n",
      "   macro avg       0.99      0.99      0.99     17959\n",
      "weighted avg       0.99      0.99      0.99     17959\n",
      "\n",
      "Test dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   True News       0.99      1.00      1.00      4247\n",
      "   Fake News       1.00      0.99      1.00      4733\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 73;\n",
       "                var nbb_unformatted_code = \"class_names = [\\\"True News\\\", \\\"Fake News\\\"]\\nprint(\\\"Assessments of the trained model:\\\")\\nprint('')\\nprint(\\\"Validation dataset:\\\")\\nclassification_report_trained = classification_report(y_true_trained, y_val_pred_trained2, target_names=class_names)\\nprint(classification_report_trained)\\nprint(\\\"Test dataset:\\\")\\nclassification_report_trained_test = classification_report(y_true_trained_test, y_test_pred_trained2, target_names=class_names)\\nprint(classification_report_trained_test)\\nprint('')\\nprint(\\\"Assessments of the fine-tuned model:\\\")\\nprint('')\\nprint(\\\"Validation dataset:\\\")\\nclassification_report_tuned = classification_report(y_true_tuned, y_val_pred_tuned2, target_names=class_names)\\nprint(classification_report_tuned)\\nprint(\\\"Test dataset:\\\")\\nclassification_report_tuned_test = classification_report(y_true_tuned_test, y_test_pred_tuned2, target_names=class_names)\\nprint(classification_report_tuned_test)\";\n",
       "                var nbb_formatted_code = \"class_names = [\\\"True News\\\", \\\"Fake News\\\"]\\nprint(\\\"Assessments of the trained model:\\\")\\nprint(\\\"\\\")\\nprint(\\\"Validation dataset:\\\")\\nclassification_report_trained = classification_report(\\n    y_true_trained, y_val_pred_trained2, target_names=class_names\\n)\\nprint(classification_report_trained)\\nprint(\\\"Test dataset:\\\")\\nclassification_report_trained_test = classification_report(\\n    y_true_trained_test, y_test_pred_trained2, target_names=class_names\\n)\\nprint(classification_report_trained_test)\\nprint(\\\"\\\")\\nprint(\\\"Assessments of the fine-tuned model:\\\")\\nprint(\\\"\\\")\\nprint(\\\"Validation dataset:\\\")\\nclassification_report_tuned = classification_report(\\n    y_true_tuned, y_val_pred_tuned2, target_names=class_names\\n)\\nprint(classification_report_tuned)\\nprint(\\\"Test dataset:\\\")\\nclassification_report_tuned_test = classification_report(\\n    y_true_tuned_test, y_test_pred_tuned2, target_names=class_names\\n)\\nprint(classification_report_tuned_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = [\"True News\", \"Fake News\"]\n",
    "print(\"Assessments of the trained model:\")\n",
    "print('')\n",
    "print(\"Validation dataset:\")\n",
    "classification_report_trained = classification_report(y_true_trained, y_val_pred_trained2, target_names=class_names)\n",
    "print(classification_report_trained)\n",
    "print(\"Test dataset:\")\n",
    "classification_report_trained_test = classification_report(y_true_trained_test, y_test_pred_trained2, target_names=class_names)\n",
    "print(classification_report_trained_test)\n",
    "print('')\n",
    "print(\"Assessments of the fine-tuned model:\")\n",
    "print('')\n",
    "print(\"Validation dataset:\")\n",
    "classification_report_tuned = classification_report(y_true_tuned, y_val_pred_tuned2, target_names=class_names)\n",
    "print(classification_report_tuned)\n",
    "print(\"Test dataset:\")\n",
    "classification_report_tuned_test = classification_report(y_true_tuned_test, y_test_pred_tuned2, target_names=class_names)\n",
    "print(classification_report_tuned_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3f315-216d-4422-bf7e-8d29a2fa2dfb",
   "metadata": {},
   "source": [
    "### Conclusions for this part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a66826",
   "metadata": {},
   "source": [
    "It can be observed that:\n",
    "- the trained model performed not well both with validation and test datasets;\n",
    "- the fine-tuned model performed quite well both with validation and test dataset (f1 score equal to 0.99 for validation and 1 for test dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c3372-651e-4e83-90c9-46e9129724d4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-text",
   "language": "python",
   "name": "tf-text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
